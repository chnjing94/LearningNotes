# 1. 基础和应用篇

## 1.1 Redis基础数据结构

Redis有5种基础数据结构，分别为：string（字符串）、list（列表）、hash（字典）、set（集合）和zset（有序集合）

底层数据结构一共6种，

![](./pic/Redis数据结构和底层实现.jpg)

### 1.1.1 String

- Redis字符串是动态字符串，可修改。
- 实现方式类似Java的ArrayList，通过预分配冗余空间来减少频繁的内存分配。
- 长度<44字节，采用embstr存储格式，长度>44字节采用Raw形式。
- 字符串长度小于1MB时，扩容是加倍现有空间。长度超过1MB时，每次扩容增加1MB的空间，字符串最大长度512MB。

### 1.1.2 List

- Redis列表相当于Java里面的LinkedList（实际底层是一种“quicklist”的快速列表），插入和删除时间复杂度为O(1)，定位查找时间复杂度O(n)。
- 元素之间使用双向指针连接，支持向前向后遍历。
- 常用来做异步队列，将任务序列化成字符串放入Redis的列表，别的线程从这个列表中轮询数据进行处理。
- ziplist是使用一块连续内存来实现链表，减少前后指针也就减少了内存使用。quicklist是将若干个ziplist双向连接起来。

### 1.1.3 Hash

- 相当于Java里的HashMap，数组+链表二维结构。
- key只能是字符串。
- 采用渐进式rehash策略，在rehash时，保留新旧两个hash，查询时会同时查两个hash，后续会定时将数据从旧的hash里移动到新的hash，迁移完成就会用新的hash代替旧的，然后回收其空间。
- 当元素数量等于桶的数量时，触发扩容。小于桶的10%时缩容。

### 1.1.4 Set

- Redis集合相当于Java语言里面的HashSet。
- 内部实现是一个value为NULL的字典，所有的键值对是无序的，唯一的。

### 1.1.5 zset

- zset，有序列表，类似于Java的SortedSet(根据score排序)和HashMap<value,score>的结合体。
- 它是一个set，可以保证内部元素(value)的唯一性。
- 可以对set里的value，根据其score进行排序。
- 内部实现是由hash字典加上一种叫做“跳表”的数据结构。

### 1.1.6 容器型数据结构通用规则

1. create if not exists：如果容器不存在就先创建一个，再进行操作。
2. drop if no elements：如果容器里没有元素，就立即删除容器，释放内存。

### 1.1.7 过期时间

Redis的所有对象都可以设置过期时间，时间到了，就会自动删除该对象。过期是以对象为单位，比如一个hash结构，过期指的是整个hash对象，而不是里面的某个key。

## 1.2 分布式锁

分布式锁是用来解决分布式应用之间的同步问题。使用Redis来实现分布式锁。

```
> setnx lock true
// 如果之前不存在lock变量，则返回1，相当于抢到了锁，否则返回0。
> del lock
// 用完之后删除lock，相当于释放锁。
```

### 1.2.1 死锁问题

如果加锁成功后，在释放锁之前出现异常，导致del指令不能被调用，这样锁永远都得不到释放。解决方法就是，在拿到锁之后，再给锁加一个过期时间，这样即使中途发生异常也可以保证锁到期后被释放。

```
> setnx lock true
> expire lock 5
···do something···
> del lock
```

但是仍然存在问题，就是拿到锁后，在设定锁过期时间之前发生异常，还是会造成死锁。

解决方法是把加锁和设置过期时间变成原子操作。

```
> setnx lock:codehole true ex5 nx
···do something···
> del lock 
```

### 1.2.2 超时问题

Redis分布式锁并不能解决超时问题，如果在加锁和释放锁之间的逻辑执行得太久，以至于超出了锁的超时限制，就会出现问题，导致临界区代码不能得到严格串行执行。为了避免这个问题，Redis分布式锁不要用于较长时间的任务。

### 1.2.3 可重入性

Redis要实现可重入性，可以对set方法进行包装，使用线程的Threadlocal变量存储当前持有锁的计数。

## 1.3 延时队列

Redis可以用来实现只有一个消费者组的消息队列，但是可靠性没有保障。使用list数据结构来作为一部消息队列使用，用rpush和lpush操作入队列，用lpop和rpop操作出队列。支持多个生产者和多个消费者并发进出消息，每个消费者拿到的消息都是不同的列表元素。

### 1.3.1 队列空了怎么办

队列空了，客户端会陷入pop的死循环，导致cpu消耗升高，通常使用sleep来解决这个问题，让线程睡一会儿再请求数据。

### 1.3.2 阻塞读

睡眠虽然可以解决空轮询问题，但是会导致消息延迟增大。因此更好的解决方案是阻塞读。使用命令`blpop/brpop`，阻塞读在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来，消息的延迟几乎为0。

### 1.3.3 空闲连接自动断开

如果阻塞读长时间阻塞，会导致长时间占用资源，因此在阻塞了一段时间后，blpop/brpop会抛出异常。

### 1.3.4 延时队列的实现

延时队列可以通过redis的zset有序列表来实现。将消息序列化成一个字符串作为zset的value，将消息的到期处理时间作为score，然后用多个线程轮询zset获取到期的任务进行处理。使用redis.zrangebyscore("delay-queue, 0, time.time(), start=0, num=1")来获取一条满足到期时间的任务。然后使用redis.zrem来抢这条任务，因为多个线程都可以使用pop命令同时读到该消息，只有这一步成功了才算抢到了任务，可以执行该任务。

### 1.3.5 进一步优化

在上面的算法中，同一个任务可能会被多个进程取到之后再使用zrem进行争抢，那些没抢到的进程都白取了一次任务，这是浪费。因此可以考虑用lua scripting来优化，将zrangbyscore和zrem一同挪到服务端进行原子化操作，这样就不会出现这种浪费了。

## 1.4 位图

Redis中实现位图的方式是`setbit/getbit`命令。

```
> setbit s 1 1
> getbit s 1
> 1
> set w h
> getbit w 1
> 1
```

### 1.4.1 统计和查找

`bitcount key [start] [end]` 统计指定区间上1的个数

`bitpos key bit [start] [end]`返回变量key中第start个到end个字符中，第一个`bit`的位置。

### 1.4.2 bitfield

bitfield指令用于一次处理多个位的操作，最多同时处理64位。

 ```
> bitfield w get u4 0  // 从第一位开始取4个位，结果是无符号数（u）
> bitfield w get u4 0  // 从第一位开始取4个位，结果是有符号数（i）
> bitfield w set u8 8 97 // 从第9个位开始，将接下来的8个位用无符号数97替换
 ```

incrby用来对指定范围的位进行自增操作。对于溢出，Redis默认是折返，如果溢出，会将溢出的符号位丢掉。bitfield提供了溢出策略子命令overflow，可以选择失败(fail)以及饱和截断(sat)，饱和截断就是保持最大值 。

##1.5 HyperLogLog

HyperLogLog是一种set，提供不精确的去重技术方案，标准误差是0.81%，每个HyperLogLog占用12K的内存。

`pfadd`增加计数，`pfcount`获取计数，`pfmerge`将多个pf计数值累加到一起。

原理：

给定一系列的随机正数，记录下低位连续零位的最大长度K，通过K值可以估算随机数的数量N。HyperLogLog使用了16384个桶来计数，每个桶的maxbits使用6个bit进行计数，最大可以表示maxbits=64，因此占用12K内存。

1. 每到来一个随机数，先确定它放到某一个桶中，这里同时也实现了去重功能。
2. 求出它的低位连续零位，和当前这个桶的最大长度maxbits作比较。
3. 使用调和平均（倒数的平均）来计算平均数，这样能有效防止个别离群值对平均结果产生较大影响，最后根据桶的数量对估值进行放大。

## 1.6 布隆过滤器

### 1.6.1 是什么

布隆过滤器，从名字上看，是一种过滤器，就像茶叶过滤器一样，过滤掉的一定是茶叶，不可能是水，而留下来的可能有细小的茶叶，同样的布隆过滤器也有微小的误判率。

从数据结构上来说，它是一种高级set，提供set的add, contains函数，不同的是，首先，元素加进去了，不能再取出来了，add方法只是让布隆过滤器见一面这个元素，而不是真正存储起来，而contains函数告诉调用者，有没有见过这个元素，当他说没有，那就一定没有见过，当他说有，那就可能见过，可能没见过。第二，相比于set，布隆过滤器能节省90%空间。

### 1.6.2 能做什么

布隆过滤器提供不完全正确的去重检查功能，适用的场景有以下几种：

- 判断用户有没有读过谋篇新闻，将用户浏览过的所有新闻都加到布隆过滤器里面，当有一篇新的新闻来的时候，去过滤器里面查一查，如果说不存在，则用户一定没看过该新闻，就推送给用户，如果存在，那么大概率用户看过，就不推送给用户，即使错了，不会造成严重后果，大不了少看一条新闻。
- 垃圾邮件判定，用户每添加一个邮件地址黑名单，就加到布隆过滤器里，来了一封新邮件，问一下过滤器，这个地址是否在黑名单里，是就放到垃圾邮件分类里，如果没有见过，就放到正常邮箱。因此，可能会出现正常邮件被误判的情况，但是垃圾邮件一定被放到了垃圾邮件分类里。

### 1.6.3 基本用法

```
> df.add codehole user1
1
> df.exists codehole user1
1
> df.exists codehole user2
0
```

### 1.6.4 实现原理

布隆过滤器由一个位数组和若干个hash函数组成。每次通过add进来一个元素，使用每个hash函数求得多个hash值，并在hash值对应的数组位置上置为1。当调用exists来查找某个元素是否存在时，又使用每个hash函数求得多个hash值，检查每个hash值对应的数组位置上的值，如果都是1，则判定为存在，如果其中任何一个位置是0，则没有见过。当数组太小，而元素太多时，数组几乎都为1，那么出现误判的几率会大大上升，但是如果判定为不存在，那么这个元素一定不存在，不会出现误判。

### 1.6.5 注意事项

布隆过滤器允许用户设定两个初始化参数：

- initial_size：初始化大小，需要用户去估计里面会装多少个元素，设置得太大，浪费存储空间，需要的hash函数数量也更大，计算效率降低。设置得太小，影响准确率。
- error_rate，错误率，设置得越小，需要的空间越大，但是仍然远远小于set所需空间。

## 1.7 限流器

### 1.7.1 为什么需要限流器

当系统的处理能力有限的时候，需要对请求数量进行限制，因此需要用到限流器。

### 1.7.2 实现方式

两种redis实现的限流器

- 第一种比较简单，使用redis的数据结构zset，将每一次请求的时间作为score，value随意，放到zset里面。当新来一个请求，需要判断它是否能够被处理。假设现在限制1S内只允许10次请求，使用`zremrangebyscore` 来移除时间戳为0-当前时间减1S的范围内的元素，剩下的就是1S之内的请求，如果数量大于10，则拒接此次请求，如果小于则处理，并加入zset。

  这种实现方法的缺点是，如果遇到这种场景，1S之内不能超过100万次，会浪费大量的空间，同时也很耗时。

- 第二种称为漏斗限流法。

  ```python
  class Funnel:
  	capacity:容量
  	leaking_rate：漏水速率
  	left_quota:剩余的水量
    leaking_ts：上次漏水时间
  ```

  我们定义一个漏斗类，拥有上述属性。现在有一个请求进来了，相当于往漏斗里加水

  1. 首先要执行一次漏水操作，也就是根据当前时间，和leaking_ts上次漏水时间的差，乘以漏水速率，算出两次加水时间间隔内，有多少水漏出去了，然后更新left_quota剩余水量，但是剩余水量不能超过总容量。同时，记录leaking_ts为当前时间。
  2. 判断这次加水操作的水量，是否会导致漏斗溢出，如果会，则拒绝加水操作，也就是拒绝请求。如果不会溢出，则执行该请求。
  3. 加水之后，更新剩余水量。

  如果用redis的hash来实现，上面这3步无法保证原子操作，势必要加锁，从而降低性能，而Redis-Cell模块，实现了漏斗算法，并提供了原子的限流指令。

  ```
  > cl.throttle laoqian:reply 15 30 60 1
  laoqian:reply 代表key
  15 代表capacity，漏斗容量
  30 60 代表漏水速率为30/60S
  1 代表此次加水量为1
  
  执行结果返回值会告诉你执行成功还是失败，漏斗总容量，剩余空间，如果被拒绝之后的重试时间，以及需要多久漏斗会完全空出来。
  ```


## 1.8 GeoHash

### 1.8.1 用来干什么

需要用到的场景就是根据地理位置，查找与自己相近的目标，例如附近的人，附近的饭店，离你最近的车。

### 1.8.2 怎么使用

Redis提供了6个Geo指令

```
> geoadd company 116 39 juejin  // 增加坐标点
> geodist company juejin ireader km //求两点的距离
> geopos company juejin // 获取任意坐标点的经纬信息
116
39
> geohash company ireader // 获取元素的经纬度编码字符串
"wx4g52e1ce0"
> georadiusbymember company ireader 20 km count 3 asc // 查询指定元素一定范围内的其他元素
```

### 1.8.3 实现原理

要查找一个元素附近的元素，如果用二维坐标表示元素位置，那么计算量会比用一维坐标系表示元素位置要大。因此，geohash算法的关键就是将二维坐标映射到一维坐标系上。映射的方式为，用二分法不断地将整个平面切成小块，每个小块赋予0或者1，这样一直分下去，编码的长度会越长，但是精度会越高。例如，一个点所在的区域编码是0100，另一个元素的编码是0101，因此这两个点的距离就是1。如果是1000和1100，他们的距离就是二进制0100，就是4。

知道如何编码之后，使用zset数据结构，value是元素，score是它的geohash编码。需要查找时按照zset的查找方式查找即可。

### 1.8.4 注意事项

在一个地图应用中，数据量可能有几百万条，甚至更多，如果使用Redis的Geo数据结构，他们将全部放到一个zset中，如果在Redis的集群环境，集合可能或从一个节点迁移到另一个节点，如果单个key过大，会降低性能，因此在集群环境下，建议单个key的数据量不超过1M，可以按照国家，省份，市来拆分。并且建议不是在单独的Redis实例上，不使用集群环境。

##1.9 scan

### 1.9.1 是什么

提供了一种查找所有符合条件的key的高性能指令。如果不用`scan`指令，redis还提供了`keys`命令来查找，该命令有以下的缺点：

1. 没有offset, limit参数，一次性输出所有符合条件的结果。
2. keys是遍历算法，复杂度是O(n)，如果实例中有千万级的keys，这个指令会导致服务卡顿，所有读写Redis的指令都将被延后甚至超时报错。

### 1.9.2 特点

1. 虽然复杂度是O(n)，但是它通过游标分步进行，不会阻塞线程。
2. 提供limit参数，控制返回结果数量。
3. 提供模式匹配功能。
4. 返回结果可能有重复。
5. 遍历过程中如果有数据修改，不一定能够被遍历到。
6. 单次返回的结果不是空的并不意味着遍历结束，而是要看返回的游标值是否为0。

### 1.9.3 用法

scan提供了三个参数，第一个是cursor游标，第二个是key的正则模式，第三个是遍历的limit hint。第一次遍历cursor是0，将返回结果中第一个整数值作为下次遍历的cursor，一直到返回的cursor的值为0结束。

```
> scan 0 match key99* count 10
1）"13976"
2）1）"key9911"
	 2）"key9974"
	 3）"key9922"
	 4）"key9933"
	 5）"key9944"
> scan 13976 match key99* count 10
1）"1996"
2）1）"key9911"
	 2）"key9974"
	 3）"key9922"
	 4）"key9933"
	 5）"key9944"
```

scan指令是一系列指令，除了可以遍历所有key之外，还可以对指定容器集合进行遍历，比如zscan遍历zset集合，hscan遍历hash字典的元素，sscan会遍历set集合的元素。实现方法类似，因为zset，hash，set内部都是用字典来存储元素。

### 1.9.4 原理

- 存储方式

  Redis中所有的key都存在一个字典中，相当于java中的hashmap，是一位数组加链表的形式存放。scan指令参数中的cursor游标，指的就是就是一位数组中的位置索引下标。limit参数就是指定遍历的数组下标个数。

- 遍历顺序

  scan遍历顺序不是从0开始，而是采用高位进位加法来遍历，之所以这样是考虑到字典的扩容和缩容时，避免重复遍历和遗漏。

- 渐进式rehash

  java的hashmap在扩容时，如果数据量很大，会出现元素卡顿现象。Redis为了解决这个问题，采用了渐进式rehash，也就是同时保留新旧字典，每次移一部分到新字典，查询的时候需要同时查找新旧字典。

# 2. 原理篇

## 2.1 线程IO模型

Redis是**单线程**程序，也就是说一个Redis实例在某一时刻只能用到一个CPU核。但是它确实是拥有高性能的一个中间件，同样是单线程高性能的有Node.js，Nginx。

### 2.1.1 单线程为什么还快

1. Redis的数据，以及操作完全在内存中完成，相比较磁盘读写，速度非常快。
2. 采用单线程，避免了上下文切换和竞争条件，不存在线程切换消耗，以及锁的竞争导致的消耗。
3. 使用多路IO复用模型，非阻塞IO。

### 2.1.2 怎么提升性能

- Redis是单线程的，一个实例只能利用一个CPU，因此应该提升单个CPU的性能，增大机器的内存。
- 启用多个Redis实例，构建Redis集群，让耗时长的操作去某一个slave节点上去执行，这样就不会影响别的任务的执行。

## 2.2 通信协议

Redis采用Redis序列化协议RESP。

###2.2.1 RESP(Redis Serialization Protocol)

Redis协议将传输的结构数据分为5种，单元结束时统一加上回车换行符\r\n

1. 单行字符串以“+”开头。
2. 多行字符串以$符号开头，后跟字符串长度。
3. 整数以“ : ”开头，后面跟整数的字符串形式。
4. 错误消息以"-"符号开头。
5. 数组以“*”号开头，后跟数组的长度。

### 2.2.2 特点

易读性，简单性，易理解性好。虽然有大量的冗余回车换行符，增大了网络传输开销，但是网络流量不是限制数据库性能的瓶颈，因此Redis还是能达到10w/s的超高QPS。

## 2.3 持久化

### 2.3.1 为什么需要持久化？

Redis中的数据都在内存中，如果突然宕机，数据会全部丢失，那么如果想要保证这些数据在宕机时保证数据不丢失，就需要持久化内存中的数据到磁盘。持久化方法分三种，分别是快照，AOF，混合方式。

### 2.3.2 快照

快照的实现过程就是，在开始持久化的时刻，制作一个内存快照，然后让子进程去将此时的内存快照写入磁盘，而主进程继续接受处理请求。

那么怎么能够瞬间制作一个内存快照，不会造成主线程卡住呢？

Redis使用了操作系统的COW(Copy on Write)机制来实现内存快照，在Linux上，会调用glibc的函数fork去产生一个子进程，那么对于这个子进程它看到的内存中的数据来说，会一直保持在fork之前，如果主进程在fork之后想要修改内存中的数据，操作系统会将该的内存页复制一份出来，在新的上面修改，保留旧的内存页，因此子进程还是看到的旧数据。如果主进程把所有的内存都更新了，内存中的数据量最多相当于fork之前的2倍。

### 2.3.3 AOF

AOF是一种日志，记录了从某个时刻开始，Redis接收的所有修改数据的指令序列。如果Redis实例宕机了，通过重放AOF日志，来恢复数据。

但是如果Redis实例运行过久，AOF日志量会越来越大。解决方法是，Redis提供了bgrewriteaof指令用于对AOF日志进行重写，实现过程是，开辟一个子进程对内存进行遍历，生成一系列Redis的操作指令，序列化到新的AOF日志中，然后将这段时间内发生的增量AOF日志，追加到新的AOF日志中，追加完毕就立即代替旧的AOF日志。

### 2.3.4 混合持久化

如果使用快照来恢复数据，那么会有大量的数据会丢失，如果使用AOF来恢复数据，会花大量时间来启动Redis。那么混合持久化机制的出现就是为了解决这个问题的，将快照文件和AOF日志放一起，AOF日志是从快照文件开始写的那一刻之后产生的增量AOF，通常这部分很小。

当重启之后，先加载快照文件，再回放AOF文件，重启的效率大大提升。

### 2.3.5 Redis运维

持久化是一个很消耗机器资源的操作，体现在

- fork操作是一个比较耗资源的操作，之后要遍历整个内存，大块写磁盘会加重系统负担。
- fsync是一个比较耗时的IO操作，降低Redis性能的同时，还增加系统IO负担。

因此，持久化通常放到备份子节点去做，子节点因为没有来自客户端的压力，它的机器资源比较充沛。

## 2.4 管道

### 2.4.1 作用

Redis的pipeline是用来应对一次业务需要多次读写redis的场景，提高这种场景下的性能。

### 2.4.2 实现

管道是在客户端实现的，与服务器端无关，服务器也不知道客户端用了管道。管道将多个读写操作重排序，多个写操作合并在一起发送，读操作全部放到后面，等到第一个read操作读到了结果，后面的read操作就可以直接从缓存中拿到结果，瞬间就返回了。

## 2.5 事务

Redis支持的事务，和关系型数据事务支持的ACID不一样，只实现了隔离性，因为Redis是单线程，事务在执行过程中，不会有其他操作影响事务的执行。Redis的事务不支持原子性，即某一步失败，会逃过并继续向下执行。

### 2.5.1 用法

- multi，开始事务。
- exec，开始执行事务。
- discard，放弃事务的执行。

从multi到exec之间的所有操作，将被放到一个队列当中，调用exec后，将顺序执行队列中的全部指令，跳过其中失败的步骤。使用discard将这个队列释放。

### 2.5.2 优化

将事务中的每一个指令缓存到事务缓存队列都要经过一次网络读写，当事务内指令很多时，需要的网络IO时间将增长，因此客户端在执行事务时，一般结合pipeline一起使用，这样将多次IO压缩为单次IO。

### 2.5.3 watch

Redis提供了一种乐观锁机制来控制并发，watch，必须在multi操作之前使用。在事务开始前，调用watch来监视这个变量，然后执行事务，如果中途被监视的变量发生变化，exec的返回结果会为NULL，代表着变量被动过了。

### 2.5.4 思考

为什么Redis的事务不能回滚？

- 因为没有类似于undo log之类的回滚日志。
- 保持简单，运行速度更快。
- 如果出错，一定是指令写错，是可以在开发阶段就能发现并解决掉。

## 2.6 内存压缩

因为Redis是一个内存数据库，不像硬盘，内存是十分有限的资源，因此Redis针对内存中的数据结构进行了大量优化。

###2.6.1 32bit vs 64bit

如果Redis使用32bit编译，那么所有的数据结构使用的指针将会减少一半的大小，因此如果你的Redis使用内存不超过4GB，就可以使用32bit进行编译。4GB容量的Redis对于小型站点的缓存数据库绰绰有余，如果不够，可能增加实例来解决。

### 2.6.2 小对象压缩存储(ziplist)

Redis的ziplist是一个紧凑的字节数组结构，如果存储的是hash结构，那么key，value会被作为两个entry被相邻存储。如果存储的是zset结构，value，score会作为两个entry被相邻存储。

当集合对象的个数不断增加，或者某个value值过大，这种小对象存储也会被升级为标准结构。

###2.6.3 内存回收机制

当你删除了Redis中的key后，操作系统并不会马上回收这一部分内存，因为操作系统是以页未单位来回收内存的，只要这个页上还有一个key在使用，那么它就不能被回收。Redis虽然不能保证立即回收已经删除的key的内存，但是可以重新使用那些尚未回收的空闲内存。

Redis采用jemalloc库来管理内存。

# 3. 集群篇

## 3.1 主从同步

在实际生产中，就算没有使用到Redis集群，也都至少使用了Redis主从复制，当主节点挂掉的时候，从节点可以接替其继续干活。以此来保障Redis的高可用性。

###3.1.1 CAP

- C：Consistent，一致性
- A：Availability，可用性
- P：Partition Tolerance，分区容忍性

因为是分布式系统，一定会满足P，就是可能因为网络故障产生分区。如果你不能容忍产生分区的现象，只能选择单机系统。

那么，根据CAP理论，上面三点只能满足任意两点，在P已经满足的情况下，要么满足一致性，要么满足可用性，难以两全。

保证一致性的话，就是在发生分区的时候，暂停写服务，这样两个分区的数据不会出现不一致，也就保障了一致性，同时，因为对外界看来系统是不可写的，因此失去了可用性。

保证可用性的话，也就是让一个分区继续处理写请求，会造成两个分区数据不一致。

### 3.1.2 CAP在Redis的实践

Redis主从架构首先是满足P的，其次，主从复制采用异步复制，主节点执行指令后，采用异步方法，复制指令到从节点。因为没有保证从节点什么时候能够跟上主节点，所以没有满足一致性要求。在从节点网络断开的时候，主节点还是可以对外提供读写服务，满足了可用性。

Redis满足的是最终一致性，也就是从节点在将来某个时刻是会跟上主节点的，比如网络恢复后，从节点会用各种策略来追上主节点。

### 3.1.3 同步方式-增量同步

Redis正常情况下采用增量模式的同步方式，将那些对自己状态产生修改的指令，保存到一个环状buffer里，并同步给从节点。从节点收到指令后，在自己的机器上应用这些指令，然后向主节点反馈自己同步到什么位置了。

因为buffer是一个环状数组，总空间是有限的，如果写满了，就必须覆盖最初的。当从节点同步的速度太慢，buffer里的指令还没同步，就被新指令给覆盖了的时候，就需要使用更复杂的同步方式——快照同步。 

### 3.1.4 快照同步

快照同步是一个非常耗费资源的操作，过程为：

1. 主节点将内存中的数据持久化到本地（Redis现在支持无盘复制，将内存中的数据直接发送给从节点），记录持久化过程中产生的新指令。
2. 将持久化数据传输到从节点，从节点应用这些数据，保存到内存中。
3. 从节点继续进行增量同步。

如果整个快照同步的过程很慢，导致产生的新指令塞满了buffer，覆盖了之前的指令，会导致重新进行快照同步。如此极有可能陷入快照同步死循环。

### 3.1.5 增加从节点

当新加入一个从节点时，先进行一次快照同步，再进行增量同步。

### 3.1.6 保证一致性

Redis之所以不能满足一致性，是因为采用了异步复制。如果想保证一致性，在Redis3.0之后可以使用wait指令，来进行同步复制。

wait可以指定至少N个从节点完成了数据同步，以及指定最多等待多长时间t。如果设置t=0，则无限等待，直到N个节点都完成了同步。

##3.2 Sentinel哨兵机制

### 3.2.1 作用

在Redis主节点宕机的时候，自动进行故障转移，选取一个从节点作为新的主节点，调整其余从节点向新的主节点同步。

### 3.2.2 为什么需要

因为发生主节点故障时，可以及时处理，不用人工去干预，保证了高可用性。

### 3.2.3 实现原理

Sentinel是一个集群，相当于一个zookeeper集群，有三个或以上的哨兵节点。Sentinel持续监控主节点的监控状态，当主节点挂掉，选择一个最优的从节点作为新的主节点。

对于客户端来说，第一次通过哨兵访问Redis时，会得到主节点的信息，再对主节点进行访问。如果访问失败，也就是主节点宕机，客户端会再次向哨兵查询最新的主节点信息，然后访问该节点。

因为主从节点采用异步复制，无法保证消息不丢失，如果主节点宕机时，还有数据没有同步到子节点，就会造成消息丢失。

### 3.2.4 使用

客户端可以向哨兵要主节点信息，也可以要从节点信息，每次返回的从节点是采用轮询的方式选择的。

当Sentinel进行主从切换后，客户端怎么知道地址变更了？

主节点挂了，会访问失败，因此会重新去向哨兵查询最新主节点信息。

如果主节点没挂，只是被转移成了从节点，那么客户端的写请求会得到ReadOnlyError异常，客户端就会断开所有连接，再次去查询哨兵新的主节点。

## 3.3 Redis集群之Codis

单个Redis提供的性能是有限的，一是单Redis实例内存不宜过大，否则当它的rdb快照文件过大，重启时，以及主从复制时，会非常耗时。二是因为Redis是单线程的，一个实例只能利用一个CPU核心。

因此，在应对高并发场景时，通常采用Redis集群的方式，使用多个Redis实例，共同提供服务。Codis的Redis集群方案的一种，另外一种是Redis Cluster。Codis是第三方厂家开发的，Redis Cluster是Redis官方开发的。

### 3.3.1 Codis工作流程

从客户端视角来看，基本可以把Codis实例当成Redis实例来对待（Codis不支持小部分的Redis指令），以前发给Redis的指令现在直接发给Codis，Codis根据目标key值，将指令转发给具体某一个Redis实例来完成操作。

因为Codis实例是没有状态的，因此可以起多个Codis来提高QPS和实现容灾。

### 3.3.2 Codis分片原理

Codis要将key转发到对应的Redis实例上，因此需要一个分片方法来确定一个key应该分到哪一个Redis实例。Codis默认将所有key分为1024个槽位，当一个key从客户端传进来的时候，先使用crc32计算得到hash值，再对1024取模得到一个余数，就是这个key对应的槽位，每个槽位都对应着一个Redis实例。然后，将该请求转发给这个槽位对应的Redis实例。

槽位的数量是可以设置的，如果集群节点较多建议设置为2048，4096。

### 3.3.3 不同Codis实例之间槽位同步

每个Codis实例都有槽位和Redis实例的映射关系，如果发生了扩容导致槽位信息变化，那么所有的Codis实例该如何保持这个信息一致呢？Codis将槽位映射关系保存在了一个外部分布式配置存储数据库里，可以是zookeeper，也支持etcd。

管理员可以通过Codis Dashboard来修改槽位和Redis实例的映射关系，Codis Proxy会监听到变化并重新同步Codis实例的槽位关系。以此来实现多个Codis实例之间的槽位信息同步。

### 3.3.4 扩容

当新的Redis实例要加入集群时，需要进行一下操作：

1. 将某些槽位中的key（以及对应的value）从现有的Redis实例中转移到新加入的Redis实例。
   - 使用`SLOTSSCAN`指令，获取槽位的所有key值，然后挨个转移到新的Redis实例上。
   - 如果在转移过程中有请求刚好打到了正在转移的槽位，因为数据有可能在旧节点，也可能在新节点，Codis对此情况的处理办法是，先强制完成该key的转移，完成之后再去新节点上请求这个key。
2. 修改槽位-Redis实例的映射关系。

### 3.3.5 自动均衡

新增Redis实例时，手工去平衡，调整槽位太麻烦。因此Codis能提供了自动均衡功能，自动平衡系统会在系统空闲的时候观察每个Redis实例对应的槽位数量，如果不平衡就会自动进行迁移。

### 3.3.6 Codis缺点

Codis为Redis带来扩容的同时，也损失了部分特性。

1. 因为key分布在不同的Redis实例中，也就不能再支持事务了，事务只能在单个Redis实例中完成。也不再支持rename操作了。
2. 为了支持扩容，单个key对应的value不宜过大，官方建议不超过1MB。
3. Codis使用了Codis Proxy作为中转层，增加了网络开销。
4. Codis的集群配置中心使用zookeeper来实现，引入了维护zookeeper的代价。

### 3.3.7 Codis优点

Codis相比于官方的Redis Cluster，设计上简单很多，将分布式的问题交给了第三方（zookeeper，etcd）去负责，自己省去了复杂的分布式一致性代码的编写维护工作。因此Codis也更易维护。

## 3.4 Redis集群之Cluster

Redis Cluster是Redis作者实现的Redis集群方案。与Codis不同的是，Redis Cluster是去中心化的，不像Codis作为一个中心来管理Redis集群。Redis Cluster每个节点负责整个集群的一部分数据，每个节点负责的数据量可能不一样。他们之间互相连接组成一个对等的集群。

### 3.4.1 访问过程

Redis Cluster将所有数据划分为16384个槽位，同样也有槽位与Redis实例的映射关系，这个映射关系是存在每个Redis节点的内存中的，而且是一致的。

对于客户端来说，访问过程如下：

1. 第一次与cluster建立连接的时候，会将槽位映射关系缓存在本地，如果发现客户端和集群的槽位信息不一致，就需要纠正机制来使其保持一致。
2. 有了槽位映射信息之后，客户端先将key使用crc16进行hash，得到一个整数值，然后对16384取模得到具体槽位。
3. 根据槽位映射关系，将请求发到具体某一个Redis实例上。

### 3.4.2 跳转

如果客户端向一个错误的节点发送指令后，该节点发现这个key不归自己管，就会返回给客户端一个MOVED指令，告诉客户端应该去某个节点的某个槽位访问这个key。

客户端收到这个MOVED指令后，会更新本地的槽位映射表，后续的请求都使用新的槽位映射表。

### 3.4.3 迁移

Redis Cluster提供了工具redis-trib可以让运维人员手动调整槽位的分配情况，迁移的过程如下：

1. 将源节点设置为migrating状态，将目标节点设置为importing状态，使用`keysinslot`指令来获取源节点槽位的所有key。
2. 对于每个key，使用`dump`指令序列化其value，然后传到目标节点，通过反序列化保存在内存中。
3. 最后将源节点的key删除。

单个key的迁移过程在源节点中是同步的，也就是开始迁移到删除key这个过程中，源节点的主线程是阻塞状态的，不对外提供服务，直到key被成功删除。

尽量保存每个key的内容很小，否则造成源节点阻塞时间过长，目标节点卡顿，从而影响集群的稳定性。

在迁移slot的过程中，客户端如果刚好访问旧节点到正在迁移的槽，过程如下：

1. 如果请求的key还留在旧节点的槽中，直接在旧节点里直接处理返回。
2. 如果该key不在旧节点里了，可能这个key在新节点里，可能根本就不存在，此时会返回一个ASKING指令重定向到新节点，要求客户端去请求新节点。之所以返回ASKING指令，而不是MOVED指令，是因为如果使用MOVED指令，新节点是不认为这个key归自己管的（因此迁移还没有完成），就会又返回一个MOVED指令重定向到旧节点，形成了重定向循环。而ASKING指令的意思是告诉新节点，一点要处理这个key的请求。

### 3.4.4 容错

Redis Cluster可以为每个主节点设置多个从节点，当主节点宕机，会把从节点提升为主节点。如果主节点没有从节点，它发生故障时，整个集群就会不可用。Redis提供了`require-full-coverage`参数来设置可以允许发生故障的节点数，让其他节点还可以对外服务。

### 3.4.5 网络抖动

网络抖动是常见的，不能因为某个节点发生连接失败就立即对其主从切换，很可能是网络发生了抖动，抖动是会在短时间内回复的。Redis Cluster提供了一种选项`cluster-node-timeout`，表示当某个节点持续timeout的时间失联时，才被认定为出现故障。

### 3.4.6 可能下线和确定下线

因为Redis Cluster是去中心化的，关于集群的事都得互相商量着来，当一个节点发现另一个节点失联了，会通过Gossip协议来广播这个可能下线（Possibly Fail）事件，当集群里大多数节点都认为这个节点失联了，结果将该节点标记为确定下线状态（Fail），并强迫集群里所有节点接受该节点下线的事实。然后对该节点进行主从切换。

### 3.4.7 集群变更感知

当服务器节点变更时，客户端应该立刻得到通知并更新自己的槽位映射表。分为以下两种情况：

1. 目标节点宕机，客户端会抛出ConnectionError，然后选择另外一个节点来重试，这时会受到MOVED指令来告知目标槽位所在的新的节点的信息。
2. 运维手动更改了集群信息，将主节点切换到了其他节点上，然后将旧的主节点下线，客户端会收到ClusterDown错误，告知当前节点所在集群不可用。客户端之后会断开所有连接，清空槽位映射关系表，等待下一条指令到来时，就会重新尝试初始化节点信息。

## 3.5 一致性Hash算法

http://www.zsythink.net/archives/1182/

# 4. 扩展篇

## 4.1 Redlock

我们知道使用setnx命令可以实现分布式锁，但是在一个Sentinel集群上，在主节点上加了锁，还没来得及同步到从节点，就宕机了。哨兵将从节点切换到主节点后，别的客户端又拿到了这个锁，这样就会出现两个客户端拥有了锁。Redlock的出现就是解决这个办法。

### 4.1.1 加锁过程

为了使用Redlock，需要多个Redis实例。加锁时，客户端会向过半节点发送set指令，只有当过半节点set成功时，就认为加锁成功。释放锁时，要向所有节点发送del指令。Redlock还需要考虑失败重试，时钟漂移等细节问题。

### 4.1.2 使用场景

如果你特别看重高可用性，希望挂掉一台Redis实例不会造成任何影响，就应该考虑使用Redlock。

### 4.1.3 代价

更多的Redis意味着性能下降，代码需要引入额外的library，运维上需要特殊对待。

## 4.2 过期策略

Redis的所有key都是可以设置过期时间的，时间一到，就会被自动删除。过程如下：

1. Redis将所有设置了过期时间的key加入到一个字典里面。
2. 定时遍历这个字典，删除过期的key。
3. 除了定时遍历删除，还会使用惰性删除策略，就是当客户端访问到这个key时，会检查它是否过期，是就删除这个key。

### 4.2.1 定时扫描策略

Redis默认每隔10秒扫描一次过期字典，过程如下：

1. 随机挑选20个key
2. 删除这20个key中已经过期的key。
3. 如果过期的key超过了这个20个key的1/4，也就是5个，就重复步骤1。

为了保证过期扫描不会过度循环，导致线程卡顿，算法增加了时间限制，默认为25ms。

如果大量的key在同一时间过期，则Redis会持续扫描过期字典。几乎每次请求都要延迟25ms以上，如果客户端将超市延迟设置得较短，就会造成大量业务异常。因此我们在设置key的过期时间时，尽量给过期时间设置在一个随机的范围。

### 4.2.2 从节点的过期策略

从节点不进行过期扫描，从节点对过期的处理是被动的，主节点在key到期时，在AOF日志里写入del指令，从节点执行这个指令来删除key。因为指令同步是异步的，如果del指令还没有及时在从节点执行，就会造成主从不一致。

## 4.3 数据淘汰策略——LRU

前面一节讨论的是key过期时的清理策略，这里讨论的情况是，当Redis到达内存上限时，采取的应对策略，如下：

- noeviction，不在继续接受写请求，只接受读和del请求，这会造成业务不可用。
- volatile-xxx，针对那些设置了过期时间的key采用的策略
  - volatile-lru，最少使用的key优先被淘汰。
  - volatile-ttl，比较key的剩余寿命ttl，ttl越小越先被淘汰。
  - volatile-random，随机淘汰设置了过期时间的key
- allkeys-xx，要淘汰的对象是全部的key
  - allkeys-lru，淘汰所有key中，最少使用的。
  - allkeys-random，随机淘汰key。

如果只拿Redis做缓存，应该使用allkeys-xx，如果想要持久化数据，应该使用volatile-xx。

### 4.3.1 LRU实现

LRU使用双向链表加字典的实现方式。在Java中，使用LinkedListHashMap来实现。

### 4.3.2 LRU优化

如果使用数据结构来实现LRU，会因为数据结构本身增加内存开销，因此在Redis中，采用了一种近似的LRU算法。算法非常简单，随机选出5个key，淘汰最少使用的key，随机选出的key数量可以设置。

这种近似算法，在数据量越大，越接近严格LRU算法。Redis 3.0增加了淘汰池，每次随机选出的key放入淘汰池，淘汰最旧的key之后，剩余的key放入淘汰池中留着下一次循环。

## 4.4 Redis的异步处理

我们知道Redis是单线程的，但是如果任何时候都只有一个线程，那么什么事都需要主线程去做，必定会降低性能，因此Redis在以下场景使用了子线程去执行异步任务

- 懒惰删除——unlink，当一个key很大时，del操作会很耗时，因此unlink指令将回收这个key的任务交给别的线程去异步执行。
- flushdb和flushall，用来删除整个数据库，也很缓慢，因此Redis4.0采用了异步执行的方式，在flushall后面加上async来交给后台线程去执行。
- AOF Sync，Redis每隔1S将AOF持久化到磁盘上，sync操作是一个耗时的操作，因此也交给了异步线程去执行。
- key的过期，LRU淘汰，rename指令的过程中会发生内存回收。因此也采用了异步处理的方式。

## 4.5保护Redis

Redis有以下几种潜在被攻击的方式：

1. 指令安全，例如keys，flushall指令。为了防止误操作，可以将指令改名，改成一个复杂的名字，或者干脆改成空字符串来禁用这条指令。
2. 端口安全，如果Redis暴露在公网，就必须保证对Redis的访问需要使用auth指令传入密码来访问。
3. Lua脚本安全，开发者应该禁用由用户输入的内容来生成Lua脚本，可能会被黑客利用来获取主机权限。
4. SSL代理，如果不使用SSL，客户端与服务器的通信可能被监听。Redis推荐使用spiped作为ssl代理。

# 5. 源码篇

## 5.5 zset与跳表

Redis的zset的内部实现是一个hash字典加一个跳表（skiplist）。hash字典用来存储value和score的对应关系。

### 5.5.1 基本结构

![](./pic/5-5跳表.jpg)

- 每一个元素（kv块）可能拥有不同的层高，例如元素3拥有L0，元素6拥有L0，L1。随着层数增加，拥有该层数的kv块数量会越来越少。
- 最底层kv块之间用双向链表串起来（上图中最底下一层的kv块之间的箭头应是双向的），按照从小到大的顺序排列。
- 同一层的kv块会用指针串起来，每一层元素的遍历都是从kv header出发。
- 共有64层，跳表会记录当前的最高层数maxLevel，很少有情况能达到64层，因为一般不会在跳表里放2的64次方个元素。

### 5.5.2 查找过程

- 从当前最高层开始，在每一层寻找那个最后一个比目标元素小的元素，直到在最后一层L0中找到期望的节点。
- 中间经过的一系列节点称为搜索路径，它是每一层最后一个比目标元素小的元素节点列表。有了这个搜索路径就可以确定新插入节点的位置。

### 5.5.3 随机层数

- 对于新插入的节点，需要确定它拥有的层数，Redis采用随机算法给它分配一个合理的层数。
- 首先，一个节点是100%拥有层数L0的，但是能够获得更大一层数的晋升几率只有25%。
- 低的晋升概率，导致了跳表的层数相对较低，在单个层上的遍历次数会稍多一点。

### 5.5.4 插入过程

- 首先要搜索出合适的插入点，将这个过程中的搜索路径找出来。
- 然后创建节点，并为这个节点随机分配一个层数，如果分配的层数高于当前跳表的最大高度，就需要更新当前最大高度。
- 将搜索路径上的节点和这个新节点通过向前向后指针串起来。

### 5.5.5 更新过程

- 调用zadd时，如果对应的value不存在，就是插入过程。
- 如果对应的value存在了，且score发生了变化，则先删除之前的元素，再插入拥有新score的元素。

### 5.5.6 删除过程

- 先找到要删除的节点，并把搜索路径找出来，对于该节点拥有的每一层的相关节点，重排一下前后指针。
- 注意可能会更新maxLevel。

### 5.5.7 元素排名

- Redis给forward指针都赋予了span属性，表示从前一个节点沿着forward指针跳到当前这个节点，中间会跳过多少个节点。Redis在插入，删除操作时都会更新span的值。
- 当要计算一个元素的排名时，只需要将搜索路径经过的所有节点的跨度span值进行叠加，就可以计算出元素的最终rank值。

## 5.6 压缩列表

目的：节约内存使用。

上层数据结构: List, hash, sorted set(zset)

![](./pic/ziplist.jpg)

压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。

一个隐患：一个元素长度更新可能导致后面元素级联更新。因为前一个元素的长度存储在后一个元素中。

## 5.7 快速列表

ziplist+linkedlist的结合体